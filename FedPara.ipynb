{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNr8AHV6ITSYUeSzt8PTYfQ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"hgHq3UpPeOqy","executionInfo":{"status":"ok","timestamp":1666623084334,"user_tz":-540,"elapsed":3330,"user":{"displayName":"Hyeon Woo Nam","userId":"08572911294116377288"}}},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import numpy as np"]},{"cell_type":"code","source":["class LowRank(nn.Module):\n","  def __init__(self,\n","               in_channels: int,\n","               out_channels: int,\n","               low_rank: int,\n","               kernel_size: int):\n","    super().__init__()\n","    self.T = nn.Parameter(\n","        torch.empty(size=(low_rank, low_rank, kernel_size, kernel_size)),\n","        requires_grad=True\n","    )\n","    self.O = nn.Parameter(\n","        torch.empty(size=(low_rank, out_channels)),\n","        requires_grad=True\n","    )\n","    self.I = nn.Parameter(\n","        torch.empty(size=(low_rank, in_channels)),\n","        requires_grad=True\n","    )\n","    self._init_parameters()\n","  \n","  def _init_parameters(self):\n","    # Initialization affects the convergence stability for our parameterization\n","    fan = nn.init._calculate_correct_fan(self.T, mode='fan_in')\n","    gain = nn.init.calculate_gain('relu', 0)\n","    std_t = gain / np.sqrt(fan)\n","\n","    fan = nn.init._calculate_correct_fan(self.O, mode='fan_in')\n","    std_o = gain / np.sqrt(fan)\n","\n","    fan = nn.init._calculate_correct_fan(self.I, mode='fan_in')\n","    std_i = gain / np.sqrt(fan)\n","\n","    nn.init.normal_(self.T, 0, std_t)\n","    nn.init.normal_(self.O, 0, std_o)\n","    nn.init.normal_(self.I, 0, std_i)\n","\n","  def forward(self):\n","    # torch.einsum simplify the tensor produce (matrix multiplication)\n","    return torch.einsum(\"xyzw,xo,yi->oizw\", self.T, self.O, self.I)\n","\n","class Conv2d(nn.Module):\n","  def __init__(self,\n","               in_channels: int,\n","               out_channels: int,\n","               kernel_size: int=3,\n","               stride: int=1,\n","               padding: int=0,\n","               bias: bool=False,\n","               ratio: float=0.0):\n","    super().__init__()\n","    self.in_channels = in_channels\n","    self.out_channels = out_channels\n","    self.kernel_size = kernel_size\n","    self.stride = stride\n","    self.padding = padding\n","    self.bias = bias\n","    self.ratio = ratio\n","    self.low_rank = self._calc_from_ratio()\n","\n","    self.W1 = LowRank(in_channels, out_channels, self.low_rank, kernel_size)\n","    self.W2 = LowRank(in_channels, out_channels, self.low_rank, kernel_size)\n","    self.bias = nn.Parameter(torch.zeros(out_channels)) if bias else None\n","\n","  def _calc_from_ratio(self):\n","    # Return the low-rank of sub-matrices given the compression ratio \n","    r1 = int(np.ceil(np.sqrt(self.out_channels)))\n","    r2 = int(np.ceil(np.sqrt(self.in_channels)))\n","    r = np.max((r1, r2))\n","\n","    num_target_params = self.out_channels * self.in_channels * \\\n","      (self.kernel_size ** 2) * self.ratio\n","    r3 = np.sqrt(\n","        ((self.out_channels + self.in_channels) ** 2) / (4 *(self.kernel_size ** 4)) + \\\n","        num_target_params / (2 * (self.kernel_size ** 2))\n","    ) - (self.out_channels + self.in_channels) / (2 * (self.kernel_size ** 2))\n","    r3 = int(np.ceil(r3))\n","    r = np.max((r, r3))\n","\n","    return r\n","\n","  def forward(self, x):\n","    # Hadamard product of two submatrices\n","    W = self.W1() * self.W2()\n","    out = F.conv2d(input=x, weight=W, bias=self.bias,\n","                 stride=self.stride, padding=self.padding)\n","    return out"],"metadata":{"id":"WytOsCJ7eelG","executionInfo":{"status":"ok","timestamp":1666625920319,"user_tz":-540,"elapsed":330,"user":{"displayName":"Hyeon Woo Nam","userId":"08572911294116377288"}}},"execution_count":38,"outputs":[]},{"cell_type":"markdown","source":["Adjusting the number of parameters given compression ratio."],"metadata":{"id":"0gp5Z6vVofxo"}},{"cell_type":"code","source":["orig_num_params = 256 * 256 * 3 * 3\n","\n","layer1 = Conv2d(256, 256, 3, 1, 1, False, 0.1)\n","layer3 = Conv2d(256, 256, 3, 1, 1, False, 0.3)\n","layer5 = Conv2d(256, 256, 3, 1, 1, False, 0.5)\n","layer7 = Conv2d(256, 256, 3, 1, 1, False, 0.7)\n","layer9 = Conv2d(256, 256, 3, 1, 1, False, 0.9)\n","\n","num1 = sum(p.numel() for p in layer1.parameters() if p.requires_grad)\n","num3 = sum(p.numel() for p in layer3.parameters() if p.requires_grad)\n","num5 = sum(p.numel() for p in layer5.parameters() if p.requires_grad)\n","num7 = sum(p.numel() for p in layer7.parameters() if p.requires_grad)\n","num9 = sum(p.numel() for p in layer9.parameters() if p.requires_grad)\n","\n","print(orig_num_params, num1, num1 / orig_num_params)\n","print(orig_num_params, num3, num3 / orig_num_params)\n","print(orig_num_params, num5, num5 / orig_num_params)\n","print(orig_num_params, num7, num7 / orig_num_params)\n","print(orig_num_params, num9, num9 / orig_num_params)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9_j-ihPAlLl8","executionInfo":{"status":"ok","timestamp":1666625920980,"user_tz":-540,"elapsed":242,"user":{"displayName":"Hyeon Woo Nam","userId":"08572911294116377288"}},"outputId":"222b59e3-9c9f-4c81-8f04-0ab5f600ade2"},"execution_count":39,"outputs":[{"output_type":"stream","name":"stdout","text":["589824 60192 0.10205078125\n","589824 178050 0.3018697102864583\n","589824 296434 0.5025804307725694\n","589824 414792 0.7032470703125\n","589824 533192 0.9039849175347222\n"]}]},{"cell_type":"markdown","source":["Feedforward test"],"metadata":{"id":"g2-Hl-YLopTF"}},{"cell_type":"code","source":["x = torch.randn(size=(1, 128, 16, 16))\n","layer = Conv2d(128, 256, 3, 1, 1, False, 0.1)\n","out = layer(x)\n","print(out.shape)\n","\n","x = torch.randn(size=(1, 128, 16, 16))\n","layer = Conv2d(128, 256, 3, 1, 1, True, 0.1)\n","out = layer(x)\n","print(out.shape)\n","\n","x = torch.randn(size=(1, 128, 16, 16))\n","layer = Conv2d(128, 128, 3, 1, 1, False, 0.1)\n","out = layer(x)\n","print(out.shape)\n","\n","x = torch.randn(size=(1, 128, 16, 16))\n","layer = Conv2d(128, 128, 3, 1, 1, True, 0.1)\n","out = layer(x)\n","print(out.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YQZ7VfdqmXRh","executionInfo":{"status":"ok","timestamp":1666625930725,"user_tz":-540,"elapsed":239,"user":{"displayName":"Hyeon Woo Nam","userId":"08572911294116377288"}},"outputId":"7fbbe58b-3028-4989-acd7-2432082fd202"},"execution_count":40,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([1, 256, 16, 16])\n","torch.Size([1, 256, 16, 16])\n","torch.Size([1, 128, 16, 16])\n","torch.Size([1, 128, 16, 16])\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"l1aZg1Eknxki"},"execution_count":null,"outputs":[]}]}